---
title: "Smoothing Models for Cats"
output: 
  github_document:
    toc: true
    toc_depth: 3
  html_document:
    keep_md: false
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.path = "md-images/cats-smo-"
)
```

# Setup

## Load Packages

```{r}
library(tidyverse)

library(ggplot2)
library(forecast)
library(smooth)

theme_set(theme_bw())
```

## Load Data & Create Time Series

* Original data ranged from Oct 2013 to Aug 2020
* Subset data to drop months after Feb 2020 (impacted by COVID-19 lockdowns).  This leaves 77 months (or 6 years and 5 months) of animal intake from Oct 2013 to Feb 2020 
* Create time-series object with data for only the intake of **cats**

```{r}
DATA_ORIGINAL <- read.csv("data/Austin_AC_Monthly_Strays.csv", stringsAsFactors = FALSE)
# str(DATA_ORIGINAL)

DATA_SUBSET <- subset(DATA_ORIGINAL, IN_YRMO <= "2020-02")

TIME_SERIES <- ts(data      = DATA_SUBSET[,c("Cat")],    # only include Cats 
                  start     = c(2013, 10), 
                  end       = c(2020,  2), 
                  frequency = 12)
```

Plot the intake of stray cats

```{r}
label_title = "Cat Stray Intake Oct 2013 - Feb 2020"
label_xaxis = "Months"
label_yaxis = "Monthly Cat Intake"

autoplot(TIME_SERIES) +
  ggtitle(label_title) +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title=""))
```

## Partition Data

* Training - 65 months or 5 years and 5 months (Oct 2013 to Feb 2019)
* Test     - last 12 months (Mar 2019 to Feb 2020)

```{r}
TS_TRNG_SET <- window(TIME_SERIES, 
                      start=c(2013, 10), 
                      end  =c(2019,  2))

TS_TEST_SET <- window(TIME_SERIES,
                      start=c(2019,  3),
                      end  =c(2020,  2))

N_TEST_SET <- length(TS_TEST_SET)

TS_TEST_SET
```

# Smoothing Models

## Simple Moving Average

Use `smooth::sma()` 

**Fit Model**

```{r}
MODEL_SMA <- sma(TS_TRNG_SET, order=NULL, holdout=FALSE, silent="none")
```

```{r}
summary(MODEL_SMA)
```

Optimal width/window is just the last 1 observation (as noted in title of chart output).  

That is not much of a moving average - the fitted/forecasted value is just equal to the prior month.

**Forecast/Predict Values for Test Set**

```{r}
FC_SMA <- forecast(MODEL_SMA, h=N_TEST_SET)
FC_SMA$mean
```

The forecast is flat - just the last value in the training data set repeats since we are not pulling in any other data points from the training set (at just a moving average of 1 value). 

Plot

* the full time series of cat intake (includes both the training and test data)
* the fitted values
* the forecast for the next 12 months

```{r}
autoplot(TIME_SERIES, color="darkgray") +
  ggtitle("Cage: Simple Moving Average (1)") +  
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  # fitted values    
  autolayer(fitted(MODEL_SMA), series="Simple Moving Average", lwd=0.5) +
  
  # forecasted values  
  autolayer(FC_SMA,            series="Simple Moving Average", PI=FALSE, lwd=1, lty=1)
```

**Assess Accuracy of Model**

```{r eval=FALSE, include=FALSE}
# forecast::accuracy(FC_SMA, TS_TEST_SET)

# didn't work on FC_SMA object
```

Manually Calculate

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_SMA$forecast)

MODEL_ACCURACY <- data.frame(
  Model    = "Simple Moving Average",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- MODEL_ACCURACY
MODEL_COMPARISON
```

Forecast not very good - happens to be a low value projected across all 12 months of the forecast period, so a lot of error.

## Simple Exponential Smoothing (Level)

This approach is inappropriate since the time series has trend and seasonality, but walk through the steps for experience.

Also, recall SES has a flat forecast beyond the one-step ahead.

Use `ses()` from `forecast` pacakge where ses, holt and hw are simply convenient wrapper functions for forecast(ets(...)).

**Fit Model & Forecast in One-Step**

```{r}
FC_SES <- forecast::ses(TS_TRNG_SET, h=N_TEST_SET)
FC_SES$model
```

```{r}
autoplot(TIME_SERIES, color="darkgray") +
  ggtitle("Cat: Simple Expo Smoothing") + 
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  # fitted values
  autolayer(fitted(FC_SES),    series="Simple Expo Smoothing", lwd=0.5) +

  # forecasted values
  autolayer(FC_SES,            series="Simple Expo Smoothing", PI=FALSE, lwd=1, lty=1)
```

Actual forecasted values.

```{r}
FC_SES$mean
```

Nearly identical to SMA (forecasted a value of 206).  The alpha smoothing parameter is nearly 1 (0.9999), which puts a ton of weight on the last value and almost no weight on prior values.  So that is pretty close to the same effect as a simple moving average of the just the last value.

```{r}
accuracy(FC_SES, TS_TEST_SET)
```

Manually Calculate

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_SES$mean)

MODEL_ACCURACY <- data.frame(
  Model    = "Simple Expo Smoothing",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

Result - equally awful!

## Holt Smoothing (Level & Trend)

Smooth level and trends.  Again not the most appropriate given our data has some seasonality.

```{r}
FC_HOLT <- forecast::holt(TS_TRNG_SET, h=N_TEST_SET, exponential = FALSE)

FC_HOLT$model
```

```{r}
autoplot(TIME_SERIES, color="darkgray") +
  ggtitle("Cat: Holt Smoothing (Level & Trend)") + 
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  # fitted values  
  autolayer(fitted(FC_HOLT),    series="Holt Smoothing", lwd=0.5) +

  # forecasted values  
  autolayer(FC_HOLT,            series="Holt Smoothing", PI=FALSE, lwd=1, lty=1)
```

Forecasted Values

Trend up a bit rather than a flat forecast.

```{r}
FC_HOLT$mean
```

```{r}
accuracy(FC_HOLT, TS_TEST_SET)
```

Manually Calculate

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_HOLT$mean)

MODEL_ACCURACY <- data.frame(
  Model    = "Holt Expo Smoothing",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

Still awful results!

## Holt Winters Smoothing (Level, Trend, Seasonality)

```{r}
FC_HW <- forecast::hw(TS_TRNG_SET, h=N_TEST_SET, 
                      exponential = FALSE,
                      seasonal    = "additive")
FC_HW$model
```

```{r}
autoplot(TIME_SERIES, color="darkgray", lty=2) +
  ggtitle("Cat: Holt-Winters Smoothing (Level, Trend & Seasonality)") +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  # fitted values
  autolayer(fitted(FC_HW),      series="Holt-Winters Smoothing", lwd=0.5) +
  
  # forecasted values
  autolayer(FC_HW,              series="Holt-Winters Smoothing", PI=FALSE, lwd=1, lty=1)
```

Much better fit/approach.  The appropriate technique matters.

```{r}
accuracy(FC_HW, TS_TEST_SET)
```

Manually Calculate

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_HW$mean)

MODEL_ACCURACY <- data.frame(
  Model    = "Holt-Winters Smoothing",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

Better!  On average, the Holt-Winters Smoothing model is off by 100 cats (about 18%) per month.

```{r}
checkresiduals(FC_HW$model)
```

## (stat) Holt Winters Smoothing (Level, Trend, Seasonality)

Use `HoltWinters()` from the `stats` package rather than the equivalent function in the `forecast` package which uses `ets()` under the covers.

Notes on difference between stats::HoltWinters() and forecast::hw()

* https://stats.stackexchange.com/questions/312811/implementation-difference-between-holtwinters-and-hw-functions-of-rs-forecast-p
* https://robjhyndman.com/hyndsight/estimation2/

**Fit Model**

```{r}
MODEL_HWstat <- stats::HoltWinters(TS_TRNG_SET)
MODEL_HWstat
```

```{r}
autoplot(MODEL_HWstat$x, series="Data", color="darkgray") +
  autolayer(MODEL_HWstat$fitted[,2], series="Level") +
  autolayer(MODEL_HWstat$fitted[,3], series="Slope") +
  autolayer(MODEL_HWstat$fitted[,4], series="Season") +

  ggtitle("Holt-Winter Smoothing Components") +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title=""))

# ggsave(filename = "figures/02_MOD_Cat_HoltWinters_Smoothing.png",
#        height=4, width=6, units="in")
```

```{r}
# autoplot(MODEL_HWstat$fitted, facets = FALSE)

autoplot(MODEL_HWstat$fitted[,1], series="Fitted", lwd=1.5) +
  autolayer(MODEL_HWstat$fitted[,2], series="Level",  lty=2, lwd=.5) +
  autolayer(MODEL_HWstat$fitted[,3], series="Slope",  lty=3, lwd=.5) +
  autolayer(MODEL_HWstat$fitted[,4], series="Season", lty=2, lwd=.5) +

  ggtitle("Holt-Winter: Fitted Values from Components") +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title=""))

# ggsave(filename = "figures/02_MOD_Cat_HoltWinters_Components.png",
#         height=4, width=6, units="in")
```

Illustrates the smoothed components (level, slope & season) are combined to produce the Holt-Winters model's fitted value. 

* The fitted value (thick red line) is simply the sum of the components.
* There is no perceptible change in the Slope component. 
* The Level component is essentially pushing up or pulling down the Seasonally smoothed component.

```{r}
FC_HWstat <- predict(MODEL_HWstat, n.ahead = N_TEST_SET)
FC_HWstat
```

```{r}
autoplot(TIME_SERIES, color="darkgray", lty=2) +
  ggtitle("Cat: (stat) Holt-Winters Smoothing (Level, Trend & Seasonality)") +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  # fitted values  
  autolayer(fitted(MODEL_HWstat)[,c("xhat")], series="stat::Holt-Winters", lwd=0.5) +
  
  # forecasted values
  autolayer(FC_HWstat,                        series="stat::Holt-Winters", lwd=1, lty=1) 
```

Plot comparison with Benchmark (Seasonal Naive)

```{r}
# create seasonal naive forecast for comparison
FC_SEASONAL_NAIVE <- snaive(TS_TRNG_SET, h=N_TEST_SET)

autoplot(TIME_SERIES, color="darkgray") +
  ggtitle("Cat: Holt-Winters vs. Seasonal Naive") +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  # fitted values
  autolayer(fitted(MODEL_HWstat)[,c("xhat")], series="Holt-Winters", lwd=0.75) +
  
  # forecasted values
  autolayer(FC_HWstat,                        series="Holt-Winters", lwd=1, lty=1) +

  # seasonal naive forecast
  autolayer(FC_SEASONAL_NAIVE,         series="Seasonal Naive", PI=FALSE, lwd=.75, lty=1)
  
# ggsave(filename = "figures/02_MOD_Cat_HoltWinters_vs_Naive.png",
#          height=4, width=6, units="in")
```

```{r eval=FALSE, include=FALSE}
# autoplot(TIME_SERIES, color="darkgray") +
# #  ggtitle(label_title) +
#   ggtitle("Cat: Forecast Comparison") +
#   xlab(label_xaxis) + ylab(label_yaxis) +
#   theme(legend.position = "bottom") +
#   guides(colour=guide_legend(title="")) +
# 
# #  autolayer(fitted(MODEL_HWstat)[,c("xhat")], series="Holt-Winters", lwd=0.5) +
#   autolayer(FC_HWstat,                        series="Holt-Winters", lwd=.75, lty=1) +
# 
# #  autolayer(fitted(MODEL_SEASONALITY), series="Regression on Seasonality", lwd=0.5) +
#   autolayer(FC_SEASONALITY,            series="Regression on Seasonality", PI=FALSE, lwd=0.75, lty=1) +
#   
# #  autolayer(fitted(FC_SEASONAL_NAIVE), series="Seasonal Naive", lwd=0.5) +
#   autolayer(FC_SEASONAL_NAIVE,         series="Seasonal Naive", PI=FALSE, lwd=0.5, lty=1)
# 
# # ggsave(filename = "figures/02_MOD_Cat_Compare.png",
# #        height=4, width=6, units="in")
```

```{r}
checkresiduals(MODEL_HWstat)
```

* Does not look like any autocorrelation.
* Histogram mostly normal distribution - peak slight above zero, a few large negative errors (-200)

**Assess Accuracy**

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_HWstat)

MODEL_ACCURACY <- data.frame(
  Model    = "stat::Holt-Winters",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

Similar accuracy as forecast's implementation of Holt-Winters Smoothing

```{r}
#write_csv(MODEL_COMPARISON, "data/results_cat_smoothing.csv")
```
