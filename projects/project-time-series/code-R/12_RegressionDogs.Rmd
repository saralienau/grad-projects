---
title: "Regression Models for Dogs"
output: 
  github_document:
    toc: true
    toc_depth: 3
  html_document:
    keep_md: false
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.path = "md-images/dogs-reg-"
)
```

# Setup

## Load Packages
```{r}
library(tidyverse)

library(ggplot2)
library(forecast)

theme_set(theme_bw())
```

## Load Data & Create Time Series

* Original data ranged from Oct 2013 to Aug 2020
* Subset data to drop months after Feb 2020 (impacted by COVID-19 lockdowns). This leaves 77 months (or 6 years and 5 months) of animal intake from Oct 2013 to Feb 2020
* Create time-series object with data for only the intake of **dogs**

```{r}
DATA_ORIGINAL <- read.csv("data/Austin_AC_Monthly_Strays.csv", stringsAsFactors = FALSE)
# str(DATA_ORIGINAL)

DATA_SUBSET <- subset(DATA_ORIGINAL, IN_YRMO <= "2020-02")

TIME_SERIES <- ts(data      = DATA_SUBSET[,c("Dog")],    # only include Dogs 
                  start     = c(2013, 10), 
                  end       = c(2020,  2), 
                  frequency = 12)
```

Plot the intake of stray dogs

```{r}
label_title = "Dog Stray Intake Oct 2013 - Feb 2020"
label_xaxis = "Months"
label_yaxis = "Monthly Dog Intake"

autoplot(TIME_SERIES) +
  ggtitle(label_title) +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title=""))
```

## Partition Data

* Training - 65 months or 5 years and 5 months (Oct 2013 to Feb 2019)
* Test     - last 12 months (Mar 2019 to Feb 2020)

```{r}
TS_TRNG_SET <- window(TIME_SERIES, 
                      start=c(2013, 10), 
                      end  =c(2019,  2))

TS_TEST_SET <- window(TIME_SERIES,
                      start=c(2019,  3),
                      end  =c(2020,  2))

N_TEST_SET <- length(TS_TEST_SET)

TS_TEST_SET
```

# Benchmark - Seasonal Naive Forecast

A seasonal naive forecast projects the last full season of the training data forward as the forecast.

```{r}
FC_SEASONAL_NAIVE <- snaive(TS_TRNG_SET, h=N_TEST_SET)

# snaive() returns an object of class forecast.  Element "mean" is the point forecast
FC_SEASONAL_NAIVE$mean
```

To confirm ... display last full season (12 months) of training data

```{r}
subset(TS_TRNG_SET, start=length(TS_TRNG_SET)-(N_TEST_SET-1))
```

Plot

* the full time series of dog intake (includes both the training and test data)
* the fitted values (basically shifts time series forward 1 season (=year in this case))
* the forecast for the next 12 months

```{r}
autoplot(TIME_SERIES, color="darkgray") +
#  ggtitle(label_title) +
  ggtitle("Dog: Seasonal Naive") +  
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +
  
  # fitted values
  autolayer(fitted(FC_SEASONAL_NAIVE), series="Seasonal Naive", lwd=0.5) +
  
  # forecasted values
  autolayer(FC_SEASONAL_NAIVE,         series="Seasonal Naive", PI=FALSE, lwd=1, lty=1)
```

Residual Diagnostics see discussion in https://otexts.com/fpp2/residuals.html

```{r}
checkresiduals(FC_SEASONAL_NAIVE)
```

**Residual Diagnostics on Seasonal Naive**

Yes, residual look like white noise. (Good)  There's a high/non-significant p-value in Ljung-Box test.  No significat autocorrelations.  Residuals approximately normally distributed.

**Assess Accuracy of Model**

`forecast::accuracy()` calculates various metrics on both training and test data sets. Interested in “Test set” results.

```{r}
accuracy(FC_SEASONAL_NAIVE, TS_TEST_SET)
```

Using RMSE, on average forecast off by 78 dogs per month (or 10% MAPE)

Manually calculate desired metrics

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_SEASONAL_NAIVE$mean)

MODEL_ACCURACY <- data.frame(
  Model    = "Seasonal Naive",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- MODEL_ACCURACY
MODEL_COMPARISON
```

# Regression Models

## Model Seasonality

**Fit Model**

Just have seasonality (months) as predictors.

```{r}
MODEL_SEASONALITY <- tslm(formula = TS_TRNG_SET ~ season,
                          data    = TS_TRNG_SET)

summary(MODEL_SEASONALITY)
```

* Adjusted R-squared: 0.203 - model explains just 20.3% of variance in data - not very good.
* Not many predictors are significant

**Forecast/Predict Values for Test Set**

```{r}
FC_SEASONALITY <- forecast(MODEL_SEASONALITY, h=N_TEST_SET)
FC_SEASONALITY$mean
```

Plot

* the full time series of dog intake (includes both the training and test data)
* the fitted values
* the forecast for the next 12 months

```{r}
autoplot(TIME_SERIES, color="darkgray") +
#  ggtitle(label_title) +
  ggtitle("Dog: Regression on Seasonality") +  
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +
  
  # fitted values  
  autolayer(fitted(MODEL_SEASONALITY), series=" Seasonality", lwd=0.5) +

  # forecasted values
  autolayer(FC_SEASONALITY,            series=" Seasonality", PI=FALSE, lwd=1, lty=1)  
```

Fitted values a little under actual values on first half of training data and a little over actual intake on second half.

For comparison, add Seasonal Naive forecast to plot.

For me, the dash line for time series help separate it and the fitted values.

```{r}
autoplot(TIME_SERIES, color="darkgray", lty=2) +
#  ggtitle(label_title) +
  ggtitle("Dog: Regression on Seasonality vs. Seasonal Naive") +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +
  
  # test set (next 12 months)
  autolayer(TS_TEST_SET, color="darkgray", lwd=1.5, lty=1) +
  
  # fitted values 
  autolayer(fitted(MODEL_SEASONALITY), series="Regression on Seasonality", lwd=0.75) +
  
  # forecasted values
  autolayer(FC_SEASONALITY,            series="Regression on Seasonality", PI=FALSE, lwd=1, lty=1) +

  # Seasonal Naive
  autolayer(FC_SEASONAL_NAIVE,         series="Seasonal Naive", PI=FALSE, lwd=.75, lty=1)

# ggsave(filename = "figures/02_MOD_Dog_SeasonReg_vs_Naive.png",
#        height=4, width=6, units="in")
```

```{r}
summary(residuals(MODEL_SEASONALITY))
checkresiduals(MODEL_SEASONALITY)
```

**Residual Diagnostics on Regression with Seasonality**

1. Residuals are correlated. Spikes beyond significance line at lag 1, 3, 6. Significant p-value (0.018 at an alpha of 0.05) from Breusch-Godfrey test (residuals are distinguishable from a white noise series)
2. Mean is zero. Multimodal? A bit left of zero and maybe at 50.

Conclusion: There is more information in time series the model is not extracting for a forecast.

**Assess Accuracy of Model**

```{r}
accuracy(FC_SEASONALITY, TS_TEST_SET)
```

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_SEASONALITY$mean)

MODEL_ACCURACY <- data.frame(
  Model    = "Seasonality",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = summary(MODEL_SEASONALITY)$adj.r.squared
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

Improvement over Seasonal Naive - cut errors in about half.  On average forecast would be off by 41 dogs per month or about 5%.

## Model Linear Trend

**Fit Model**

```{r}
MODEL_SEASON_LIN_TREND <- tslm(formula = TS_TRNG_SET ~ season + trend,
                               data    = TS_TRNG_SET)

summary(MODEL_SEASON_LIN_TREND)
```

* Adjusted R-squared: 0.3381 (vs 0.203) - model explains 33.8%. Improving but still not very good.
* The trend predictor is significant

**Forecast/Predict Values for Test Set**

```{r}
FC_SEASON_LIN_TREND <- forecast(MODEL_SEASON_LIN_TREND, h=N_TEST_SET)
FC_SEASON_LIN_TREND$mean
```

```{r}
autoplot(TIME_SERIES, color="darkgray", lty=2) +
#  ggtitle(label_title) +
  ggtitle("Dog: Regression on Seasonality+Linear Trend") +  
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +
  
  # test set (next 12 months)
  autolayer(TS_TEST_SET, color="darkgray", lwd=.75, lty=1) +

  # fitted values
  autolayer(fitted(MODEL_SEASON_LIN_TREND), series="Season+Linear Trend", lwd=0.75) +
  
  # forecasted values
  autolayer(FC_SEASON_LIN_TREND,            series="Season+Linear Trend", PI=FALSE, lwd=1, lty=1) 
```

The linear trend predictor (coefficient -1.05) causes the fitted & forecasted values to shift down slightly over time (AKA a slight linear trend).

```{r}
summary(residuals(MODEL_SEASON_LIN_TREND))
checkresiduals(MODEL_SEASON_LIN_TREND)
```

**Residual Diagnostics on Regression with Seasonality+Linear Trend**

1. Residuals are NOT correlated. No spikes beyond significance line. Border line significant p-value (0.0458 at an alpha of 0.05) from Breusch-Godfrey test (residuals are NOT strongly distinguishable from a white noise series)
2. Mean is zero. Histogram - kind of a normal distribution strong concentration in the center and then some values out in the tails

Conclusion: There may be some information in time series the model is not extracting for a forecast, but not a ton via residual analysis.

**Assess Accuracy of Model**

```{r}
accuracy(FC_SEASON_LIN_TREND, TS_TEST_SET)
```

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_SEASON_LIN_TREND$mean)

MODEL_ACCURACY <- data.frame(
  Model = "Season+Linear Trend",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = summary(MODEL_SEASON_LIN_TREND)$adj.r.squared  
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

The trend predictor makes the model less accurate - back on par with the seasonal naive.  The time series is not linearly trending down.  Reviewing decomposition, dog intake "trend-cycle" was declining through 2017, then trending up again in 2018 and starting to decline again in 2019.

## Model Polynomial

Try a polynomial trend

```{r}
MODEL_SEASON_POLY_TREND <- tslm(formula = TS_TRNG_SET ~ season + trend + I(trend^2), #+ I(trend^3),
                                data    = TS_TRNG_SET)

summary(MODEL_SEASON_POLY_TREND)
```

* Adjusted R-squared: 0.3659 (vs 0.3381 with linear trend) - model explains 36.6%. Improving, but still not very great.
* The trend predictors are slightly significant

```{r}
FC_SEASON_POLY_TREND <- forecast(MODEL_SEASON_POLY_TREND, h=N_TEST_SET)
FC_SEASON_POLY_TREND$mean
```

```{r}
autoplot(TIME_SERIES, color="darkgray", lty=2) +
#  ggtitle(label_title) +
  ggtitle("Dog: Regression on Seasonality+Polynomial Trend") +  
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  # test set (next 12 months)
  autolayer(TS_TEST_SET, color="darkgray", lwd=.75, lty=1) +

  # fitted values    
  autolayer(fitted(MODEL_SEASON_POLY_TREND), series="Season+Poly Trend", lwd=0.75) +

  # forecasted values  
  autolayer(FC_SEASON_POLY_TREND,            series="Season+Poly Trend", PI=FALSE, lwd=1, lty=1) 
```

```{r}
summary(residuals(MODEL_SEASON_POLY_TREND))
checkresiduals(MODEL_SEASON_POLY_TREND)
```

**Residual Diagnostics on Regression with Seasonality+Poly Trend**

1. Residuals correlated to a degree. One spike beyond significance line (lag 16). Significant p-value (0.0177 at an alpha of 0.05) from Breusch-Godfrey test (residuals are distinguishable from a white noise series)
2. Mean is zero. Histogram - peak in bar just above zero, but wider on negative side.  A bump just under 100.

Conclusion: There may be some information in time series the model is not extracting for a forecast.

**Assess Accuracy of Model**

```{r}
accuracy(FC_SEASON_POLY_TREND, TS_TEST_SET)
```

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_SEASON_POLY_TREND$mean)

MODEL_ACCURACY <- data.frame(
  Model    = "Season+Poly Trend",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = summary(MODEL_SEASON_POLY_TREND)$adj.r.squared 
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

The trend in the time series is more polynomial in nature than linear.  This model is back on par with the seasonal model, although slightly less accurate.  There is not strong justification to keep the added complexity of the poly trend, better to go with simplier model (just seasonality).

## Model Seasonality + ARIMA Error Correction

There is some autocorrelation in residuals in Seasonal Regression model above.

```{r}
#checkresiduals(MODEL_SEASONALITY)

STG_1_RESIDUALS <- residuals(MODEL_SEASONALITY)

ggAcf(STG_1_RESIDUALS) + 
  ggtitle("ACF on Residuals from Regression on Seasonality")

# ggsave(filename = "figures/02_MOD_Dog_ACF.png",
#        height=4, width=6, units="in")
```

Create a second stage ARIMA model on residuals

```{r}
#MODEL_STG2_ARIMA <- auto.arima(STG_1_RESIDUALS, seasonal=FALSE)
MODEL_STG2_ARIMA <- Arima(STG_1_RESIDUALS, order = c(1,0,0)) 

summary(MODEL_STG2_ARIMA)
```

```{r}
FC_STG2_ARIMA <- forecast(MODEL_STG2_ARIMA, h=N_TEST_SET)

label_series <- "ARIMA(0,1,1)"
autoplot(STG_1_RESIDUALS, color="darkgray") +
  ggtitle("Stage 1 Residuals") +
  xlab("Months") + ylab("Residuals") +

  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +
  
  autolayer(fitted(FC_STG2_ARIMA),    series=label_series, lwd=.5) +
  autolayer(FC_STG2_ARIMA,            series=label_series, lwd=.75, lty=2, PI=FALSE) 
```

```{r}
FC_STG2_ARIMA$mean
```

The residual correction is not very big, won't have much impact on accuracy of combined model.

```{r}
FC_SEASONALITY_ARIMA <- FC_SEASONALITY$mean + FC_STG2_ARIMA$mean

autoplot(TIME_SERIES, color="darkgray") +
#  ggtitle(label_title) +
  ggtitle("Dog: Regression on Seasonality+ARIMA Error Correction") +  
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +
  
  #autolayer(fitted(MODEL_SEASONALITY), series="Seasonality", lwd=1) +
  autolayer(FC_SEASONALITY_ARIMA,      series="Seasonality+ARIMA",     lwd=1,   lty=1) +
  autolayer(FC_SEASONALITY,            series="Seasonality", PI=FALSE, lwd=.5,  lty=2) 
```

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_SEASONALITY_ARIMA)

MODEL_ACCURACY <- data.frame(
  Model    = "Seasonality+ARIMA",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

A tiny bit more accurate - on average, forecast will reduce error by one dog per month (40 vs 41).  That level of improvement is not worth the complexity of a two stage model.

## ARIMA

In class, we did not cover ARIMA models in depth.  It is a substantial topic in its own right.

Here, I'm am just throwing in example of walking through the steps.

```{r}
MODEL_ARIMA <- auto.arima(TS_TRNG_SET)

summary(MODEL_ARIMA)
```

```{r}
FC_ARIMA <- forecast(MODEL_ARIMA, h=N_TEST_SET)
#FC_ARIMA
```

```{r}
label_series <- "ARIMA(0,1,1)(1,0,0)[12]"

autoplot(TIME_SERIES, color="darkgray") +
  ggtitle(label_title) +
  xlab(label_xaxis) + ylab(label_yaxis) +
  theme(legend.position = "bottom") +
  guides(colour=guide_legend(title="")) +

  autolayer(fitted(MODEL_ARIMA), series=label_series, lwd=.75) +
  autolayer(FC_ARIMA,            series=label_series, PI=FALSE, lwd=1, lty=1) +
  
  #autolayer(fitted(MODEL_SEASONALITY), series="Seasonality", lwd=1) +
  autolayer(FC_SEASONALITY,            series="Seasonality", PI=FALSE, lwd=.75, lty=1) 
```

```{r}
checkresiduals(MODEL_ARIMA)
```

```{r}
ACTUAL    <- as.numeric(TS_TEST_SET)
PREDICTED <- as.numeric(FC_ARIMA$mean)

MODEL_ACCURACY <- data.frame(
  Model    = "ARIMA",
  RMSE     = Metrics::rmse(ACTUAL, PREDICTED),
  MAE      = Metrics::mae( ACTUAL, PREDICTED),
  MAPE     = Metrics::mape(ACTUAL, PREDICTED),
  AdjRsqrd = NA
)

MODEL_COMPARISON <- rbind(MODEL_COMPARISON, MODEL_ACCURACY)
MODEL_COMPARISON
```

```{r}
#write_csv(MODEL_COMPARISON, "data/results_dog_regresssion.csv")
```